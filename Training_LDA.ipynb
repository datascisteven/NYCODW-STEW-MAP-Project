{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_tweets.pickle', 'rb') as read_file:\n",
    "    df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20180    [congrats, lead, nonprofit, organization, dedi...\n",
       "17391    [youre, pet, owner, new, york, know, toxic, in...\n",
       "9976                 [restock, feel, good, brooklynwineco]\n",
       "6257     [since, percent, excess, heat, retain, earth, ...\n",
       "6245     [shorebird, watch, big, business, new, jersey,...\n",
       "                               ...                        \n",
       "11964    [ooh, yourcbdstorebk, union, berkeley, cbd, st...\n",
       "21575    [meet, horticultural, therapist, garden, progr...\n",
       "5390     [alone, together, gowanus, community, group, s...\n",
       "860      [new, york, city, experience, dangerous, heat,...\n",
       "15795    [congratulations, raise, money, thank, partici...\n",
       "Name: tweet, Length: 17672, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(df.tweet, test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19530    [bundle, new, yorkers, go, dip, freeze, every,...\n",
       "20241    [congratulations, award, grant, historic, hous...\n",
       "15031                            [refresh, flower, street]\n",
       "9960     [mask, thermometers, oximeters, near, ave, bea...\n",
       "735      [deeply, thankful, haul, trash, recycle, treat...\n",
       "                               ...                        \n",
       "16606      [get_repost, member, dl, dd, show, chefs, take]\n",
       "21677    [know, secure, food, box, family, four, please...\n",
       "7948                                  [missamericanpienyc]\n",
       "4630     [dont, trash, tree, mulch, drop, bbp, anytime,...\n",
       "8439     [virtual, learn, great, option, yourchild, lea...\n",
       "Name: tweet, Length: 4418, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_of_lists = list(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(train_list_of_lists, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[train_list_of_lists], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bounty'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = Dictionary(train_list_of_lists)\n",
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in train_list_of_lists]\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.019*\"water\" + 0.010*\"river\" + 0.008*\"protect\" + 0.008*\"new\" + '\n",
      "  '0.008*\"clean\" + 0.006*\"state\" + 0.006*\"hudson\" + 0.006*\"environmental\" + '\n",
      "  '0.006*\"society\" + 0.006*\"littoral\"'),\n",
      " (1,\n",
      "  '0.014*\"us\" + 0.011*\"new\" + 0.011*\"thank\" + 0.010*\"join\" + 0.009*\"today\" + '\n",
      "  '0.009*\"get\" + 0.008*\"day\" + 0.008*\"make\" + 0.008*\"help\" + 0.008*\"learn\"'),\n",
      " (2,\n",
      "  '0.025*\"park\" + 0.016*\"brooklyn\" + 0.012*\"st\" + 0.010*\"come\" + '\n",
      "  '0.009*\"get_repost\" + 0.008*\"slope\" + 0.008*\"good\" + 0.008*\"corner\" + '\n",
      "  '0.007*\"amaze\" + 0.007*\"house\"'),\n",
      " (3,\n",
      "  '0.011*\"high\" + 0.010*\"line\" + 0.009*\"june\" + 0.008*\"friday\" + '\n",
      "  '0.008*\"ticket\" + 0.007*\"april\" + 0.006*\"bio\" + 0.006*\"business\" + '\n",
      "  '0.006*\"update\" + 0.006*\"staff\"')]\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=id2word,\n",
    "                     num_topics=4, \n",
    "                     random_state=42,\n",
    "                     chunksize=100,\n",
    "                     passes=100,\n",
    "                     update_every=5,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.28826282195420916\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=train_list_of_lists, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.42466773753051157),\n",
      " (1, 0.1766020120629213),\n",
      " (2, 0.23014024341235387),\n",
      " (3, 0.2832750364803111),\n",
      " (4, 0.2366724011621648),\n",
      " (5, 0.2832750364803111),\n",
      " (6, 0.18979599067454203),\n",
      " (7, 0.2143401059677086),\n",
      " (8, 0.24462258623808159),\n",
      " (9, 0.33186344059309086),\n",
      " (10, 0.29674778220154957),\n",
      " (11, 0.19428450256362492),\n",
      " (12, 0.19638562074430463),\n",
      " (13, 0.24300529787323882),\n",
      " (14, 0.2088991128043566)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.009*\"us\" + 0.008*\"join\" + 0.007*\"learn\" + 0.005*\"park\" + 0.005*\"program\" + 0.004*\"nyc\" + 0.004*\"come\" + 0.004*\"get\" + 0.004*\"see\" + 0.004*\"new\"\n",
      "Topic: 1 \n",
      "Words: 0.009*\"day\" + 0.006*\"open\" + 0.005*\"see\" + 0.005*\"time\" + 0.005*\"us\" + 0.005*\"new\" + 0.005*\"get\" + 0.005*\"make\" + 0.004*\"park\" + 0.004*\"saturday\"\n",
      "Topic: 2 \n",
      "Words: 0.008*\"water\" + 0.007*\"park\" + 0.006*\"help\" + 0.006*\"please\" + 0.006*\"us\" + 0.006*\"make\" + 0.006*\"get\" + 0.006*\"work\" + 0.005*\"today\" + 0.005*\"thank\"\n",
      "Topic: 3 \n",
      "Words: 0.016*\"new\" + 0.010*\"thank\" + 0.007*\"today\" + 0.007*\"us\" + 0.006*\"open\" + 0.005*\"brooklyn\" + 0.005*\"get\" + 0.005*\"york\" + 0.005*\"one\" + 0.005*\"order\"\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus, num_topics=4, id2word=id2word, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prepare',\n",
       " 'memorial',\n",
       " 'day',\n",
       " 'formerly',\n",
       " 'know',\n",
       " 'decoration',\n",
       " 'day',\n",
       " 'search',\n",
       " 'historic',\n",
       " 'newspapers',\n",
       " 'nehfunded']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_doc_300 = X_train[300]\n",
    "bow_doc_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7345105409622192\t \n",
      "Topic: 0.008*\"water\" + 0.007*\"park\" + 0.006*\"help\" + 0.006*\"please\"\n",
      "\n",
      "Score: 0.09021734446287155\t \n",
      "Topic: 0.009*\"day\" + 0.006*\"open\" + 0.005*\"see\" + 0.005*\"time\"\n",
      "\n",
      "Score: 0.08998871594667435\t \n",
      "Topic: 0.016*\"new\" + 0.010*\"thank\" + 0.007*\"today\" + 0.007*\"us\"\n",
      "\n",
      "Score: 0.08528342843055725\t \n",
      "Topic: 0.009*\"us\" + 0.008*\"join\" + 0.007*\"learn\" + 0.005*\"park\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[corpus[300]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.003*\"open\" + 0.003*\"thank\" + 0.002*\"new\" + 0.002*\"see\" + 0.002*\"today\" + 0.002*\"water\" + 0.002*\"get\" + 0.002*\"great\" + 0.002*\"day\" + 0.002*\"park\"\n",
      "Topic: 1 Word: 0.004*\"us\" + 0.003*\"join\" + 0.003*\"open\" + 0.003*\"get\" + 0.003*\"new\" + 0.003*\"day\" + 0.002*\"please\" + 0.002*\"help\" + 0.002*\"make\" + 0.002*\"thank\"\n",
      "Topic: 2 Word: 0.003*\"park\" + 0.003*\"thank\" + 0.003*\"today\" + 0.003*\"get\" + 0.002*\"see\" + 0.002*\"new\" + 0.002*\"day\" + 0.002*\"us\" + 0.002*\"open\" + 0.002*\"come\"\n",
      "Topic: 3 Word: 0.004*\"thank\" + 0.004*\"new\" + 0.003*\"today\" + 0.003*\"park\" + 0.003*\"water\" + 0.002*\"us\" + 0.002*\"support\" + 0.002*\"join\" + 0.002*\"start\" + 0.002*\"learn\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=4, id2word=id2word, passes=2, workers=4)\n",
    "\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7292246222496033\t \n",
      "Topic: 0.004*\"thank\" + 0.004*\"new\" + 0.003*\"today\" + 0.003*\"park\"\n",
      "\n",
      "Score: 0.0921914353966713\t \n",
      "Topic: 0.003*\"open\" + 0.003*\"thank\" + 0.002*\"new\" + 0.002*\"see\"\n",
      "\n",
      "Score: 0.08941055834293365\t \n",
      "Topic: 0.004*\"us\" + 0.003*\"join\" + 0.003*\"open\" + 0.003*\"get\"\n",
      "\n",
      "Score: 0.08917337656021118\t \n",
      "Topic: 0.003*\"park\" + 0.003*\"thank\" + 0.003*\"today\" + 0.003*\"get\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[corpus[300]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 4)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53e0a93b7c64fcbbd161567d178793b8bdbd3decf5b1e60d467119eca94f2238"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('geo-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
